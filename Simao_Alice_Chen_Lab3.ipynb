{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s449_PFOGpUl"
      },
      "source": [
        "# Gradient Descent Optimization\n",
        "\n",
        "In the ``demo_breast_cancer.ipynb``, we used the `sklearn` built-in `LogisticRegression` class to find the weights for the logistic regression problem.   The `fit` routine in that class has an *optimizer* to select the weights to best match the data.  To understand how that optimizer works, in this demo, we will build a very simple gradient descent optimizer from scratch.  You will learn to:\n",
        "* Compute the gradients of a loss function and implement the gradient calculations in python\n",
        "* Implement a simple gradient descent optimizer\n",
        "* Visualize the effect of the learning rate in gradient descent\n",
        "* Implement an adaptive learning rate algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWRgRAYHGpUn"
      },
      "source": [
        "## Loading the Breast Cancer Data\n",
        "\n",
        "We first load the standard packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ipls97uAGpUo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krbj0ZAqGpUp"
      },
      "source": [
        "We next load the data from the [breast cancer demo](../logistic/breast_cancer.ipynb).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipynRLbEGpUq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2f96658d-ce27-47a3-f139-6a98036cd19a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id  thick  size_unif  shape_unif  marg  cell_size  bare  chrom  \\\n",
              "0  1000025      5          1           1     1          2   1.0      3   \n",
              "1  1002945      5          4           4     5          7  10.0      3   \n",
              "2  1015425      3          1           1     1          2   2.0      3   \n",
              "3  1016277      6          8           8     1          3   4.0      3   \n",
              "4  1017023      4          1           1     3          2   1.0      3   \n",
              "\n",
              "   normal  mit  class  \n",
              "0       1    1      2  \n",
              "1       2    1      2  \n",
              "2       1    1      2  \n",
              "3       7    1      2  \n",
              "4       1    1      2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-894a1e44-d222-42b5-8950-a72781f579f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>thick</th>\n",
              "      <th>size_unif</th>\n",
              "      <th>shape_unif</th>\n",
              "      <th>marg</th>\n",
              "      <th>cell_size</th>\n",
              "      <th>bare</th>\n",
              "      <th>chrom</th>\n",
              "      <th>normal</th>\n",
              "      <th>mit</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000025</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1002945</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>10.0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1015425</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1016277</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1017023</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-894a1e44-d222-42b5-8950-a72781f579f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-894a1e44-d222-42b5-8950-a72781f579f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-894a1e44-d222-42b5-8950-a72781f579f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ],
      "source": [
        "names = ['id','thick','size_unif','shape_unif','marg','cell_size','bare',\n",
        "         'chrom','normal','mit','class']\n",
        "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/' +\n",
        "                 'breast-cancer-wisconsin/breast-cancer-wisconsin.data',\n",
        "                names=names,na_values='?',header=None)\n",
        "df = df.dropna()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5B77gpcPGpUr"
      },
      "source": [
        "As in the breast cancer demo, we create a data matrix `X` of various features of the breast cancer sample.  The response vector `y` is a binary indicating if each sample is benign or malignant.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9ULFQ8vGpUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1cd1b86-2c3c-4739-e0c8-b3f1a5175d6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 5.  1.  1. ...  3.  1.  1.]\n",
            " [ 5.  4.  4. ...  3.  2.  1.]\n",
            " [ 3.  1.  1. ...  3.  1.  1.]\n",
            " ...\n",
            " [ 5. 10. 10. ...  8. 10.  2.]\n",
            " [ 4.  8.  6. ... 10.  6.  1.]\n",
            " [ 4.  8.  8. ... 10.  4.  1.]]\n",
            "[[ 1.  5.  1. ...  3.  1.  1.]\n",
            " [ 1.  5.  4. ...  3.  2.  1.]\n",
            " [ 1.  3.  1. ...  3.  1.  1.]\n",
            " ...\n",
            " [ 1.  5. 10. ...  8. 10.  2.]\n",
            " [ 1.  4.  8. ... 10.  6.  1.]\n",
            " [ 1.  4.  8. ... 10.  4.  1.]]\n"
          ]
        }
      ],
      "source": [
        "# Get the predictors\n",
        "xnames = ['thick','size_unif','shape_unif','marg','cell_size','bare',\n",
        "         'chrom','normal','mit']\n",
        "Xraw = np.array(df[xnames])\n",
        "print(Xraw)\n",
        "\n",
        "# As usual, let's also append an all ones vector onto X to serve as the intercept feature\n",
        "X = np.concatenate((np.ones((Xraw.shape[0],1)),Xraw),axis=1)\n",
        "print(X)\n",
        "# Get the response.  Convert to a zero-one indicator \n",
        "yraw = np.array(df['class'])\n",
        "BEN_VAL = 2   # value in the 'class' label for benign samples\n",
        "MAL_VAL = 4   # value in the 'class' label for malignant samples\n",
        "y = (yraw == MAL_VAL).astype(int) # now y has values of 0,1 \n",
        "Iben = (y==0)\n",
        "Imal = (y==1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRbLSpsbGpUs"
      },
      "source": [
        "We want to learn the classification rule to predict `y` from `X`.  We will do so with logistic regression."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgUmpIGtGpUt"
      },
      "source": [
        "## Computing the Gradient and Loss Function\n",
        "\n",
        "Recall that training a logistic function means finding a weight vector $\\beta$ for the classification rule:\n",
        "* Predict 1 for data vector $\\mathbf{x}$ if $\\frac{1}{1 + e^{-\\mathbf{x}^T\\boldsymbol{\\beta}}} > 1/2$, i.e. if $\\mathbf{x}^T\\boldsymbol{\\beta} > 0$. \n",
        "* Predict 0 for data vector $\\mathbf{x}$ if $\\frac{1}{1 + e^{-\\mathbf{x}^T\\boldsymbol{\\beta}}} \\leq 1/2$, i.e. if $\\mathbf{x}^T\\boldsymbol{\\beta} \\leq 0$.\n",
        "\n",
        "Let $h(\\mathbf{x}^T\\boldsymbol{\\beta}) = \\frac{1}{1 + e^{-\\mathbf{x}^T\\boldsymbol{\\beta}}}$. To find $\\beta$, we minimize the cross-entropy loss (aka the logistic loss):\n",
        "$$\n",
        "L(\\boldsymbol{\\beta}) = - \\sum_{i=1}^n y_i \\log(h(\\mathbf{x}_i^T\\boldsymbol{\\beta})) + (1-y_i) \\log(1-h(\\mathbf{x}_i^T\\boldsymbol{\\beta})).\n",
        "$$\n",
        "As mentioned in class we have\n",
        "$$\n",
        "\\nabla L(\\boldsymbol{\\beta}) = \\mathbf{X}^T(h(\\mathbf{X}\\boldsymbol{\\beta}) - y)\n",
        "$$\n",
        "where $h(\\mathbf{X}\\boldsymbol{\\beta})$ denotes the vector obtained by applying $h$ to every entry in the vector $\\mathbf{X}\\boldsymbol{\\beta}$. \n",
        "    \n",
        "    \n",
        "We will first write a function to compute `L` and its gradient `Lgrad`. One issue we will find is that directly computing `L` using the expression above can be *numerically unstable*. Essentially what can happen is you end up taking logs of numbers very close to zero and Python will return NaNs due to issues with using finite precision arithmetic. To deal with this problem, we write down an alternative expression for `L` which is *mathematically equivalent* but can be computed more accurately in finite precision arithmetic:\n",
        "$$\n",
        "L(\\boldsymbol{\\beta}) = \\sum_{i=1}^n (1-y_i)(\\mathbf{x}_i^T\\boldsymbol{\\beta}) - \\log(h(\\mathbf{x}_i^T\\boldsymbol{\\beta})).\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Mqae-pPGpUu"
      },
      "outputs": [],
      "source": [
        "def Leval(beta,X,y):\n",
        "    \"\"\"\n",
        "    Compute the loss and gradient given beta,X,y\n",
        "    \"\"\"\n",
        "    z = X@beta \n",
        "    # 𝐱𝑇𝑖𝜷\n",
        "    h = 1/(1+np.exp(-z))\n",
        "    L = np.sum((1-y)*z - np.log(h))\n",
        "\n",
        "    # Gradient\n",
        "    Lgrad = (X.T)@(h-y)\n",
        "    return L, Lgrad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dOhVzcAGpUv"
      },
      "source": [
        "We can test our function on a random parameter vector $\\boldsymbol{\\beta}_0$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QTePmOOGpUv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f931ab4e-544c-4ce6-ae2e-49b86ed1cd70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6378.370557523656\n"
          ]
        }
      ],
      "source": [
        "# Some random point\n",
        "p = X.shape[1]\n",
        "beta0 = np.random.randn(p)\n",
        "\n",
        "# Call the function\n",
        "L, Lgrad = Leval(beta0,X,y)\n",
        "print(L)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NZQOt9rGpUv"
      },
      "source": [
        "It's not ideal that the loss function `L(beta,X,y)` depends on the parameters `X` and `y`.  Most numerical optimizers expect a function that only depends on `beta`. We can acheive this by using a Python `lambda` function to fix the parameters `X` and `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BD1wd5C8GpUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59469b79-1a5b-4e26-e6d6-c33435e9eab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6378.370557523656\n"
          ]
        }
      ],
      "source": [
        "# Create a function with X,y fixed\n",
        "Leval_param = lambda beta: Leval(beta,X,y)\n",
        "\n",
        "# You can now pass a parameter like w0\n",
        "L0, Lgrad0 = Leval_param(beta0)\n",
        "print(L0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKnnsgvxGpUw"
      },
      "source": [
        "### Testing the gradient\n",
        "\n",
        "Whenever you write a function for computing a gradient, it is very important to test if the gradient is correct.  This is a common reason people's code does not work with numerical optimizers. We saw one way of doign this using a finite difference method here: https://drive.google.com/file/d/1OjJFbyn59kxIIbAtAGRYZ6bv1RCgerC7/view?usp=sharing. Another simple method is to take two points `beta0` and `beta1` that are close to one another and then verify that:\n",
        "$$\n",
        "L(\\boldsymbol{\\beta}_1) - L(\\boldsymbol{\\beta}_0) \\approx \\langle \\nabla L(\\boldsymbol{\\beta}_0), \\boldsymbol{\\beta}_1 - \\boldsymbol{\\beta}_0\\rangle.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDxizKO5GpUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3381e9cc-bfe5-4802-d2f2-c026683fa36b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual L1-L0    =  -8.6326e-05\n",
            "Predicted L1-L0 =  -8.6326e-05\n"
          ]
        }
      ],
      "source": [
        "# Take a random initial point\n",
        "# Take a random beta0 \n",
        "p = X.shape[1]\n",
        "beta0 = np.random.randn(p)\n",
        "\n",
        "# Perturb the point\n",
        "step = 1e-6\n",
        "beta1 = beta0 + step*np.random.randn(p)\n",
        "\n",
        "# Measure the function and gradient at w0 and w1\n",
        "L0, Lgrad0 = Leval_param(beta0)\n",
        "L1, Lgrad1 = Leval_param(beta1)\n",
        "\n",
        "# Predict the amount the function should have changed based on the gradient\n",
        "dL_est = Lgrad0.T@(beta1-beta0)\n",
        "\n",
        "# Print the two values to see if they are close\n",
        "print(\"Actual L1-L0    = %12.4e\" % (L1-L0))\n",
        "print(\"Predicted L1-L0 = %12.4e\" % dL_est)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MeoNFmpGpUx"
      },
      "source": [
        "You can see that the two agree well. You can run the block multiple times to get different answers (depending on the random choice of $\\boldsymbol{\\beta}_0$, but you should always see agreement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv1xIunDGpUy"
      },
      "source": [
        "## A Simple Gradient Descent Optimizer\n",
        "\n",
        "Now, we build a simple gradient descent optimizer function with a fixed learning rate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gw8u34OuGpUy"
      },
      "outputs": [],
      "source": [
        "def grad_opt_simp(grad_func, beta0, lr=1e-3,nit=1000):\n",
        "    \"\"\"\n",
        "    Simple gradient descent optimization\n",
        "    \n",
        "    grad_func:  A function that returns the objective function L, and its gradient Leval\n",
        "    beta0:  Initial estimate for parameters beta\n",
        "    lr:     learning rate\n",
        "    nit:    Number of iterations\n",
        "    \"\"\"\n",
        "    # Create history dictionary for tracking progress per iteration.\n",
        "    # This isn't necessary if you just want the final answer, but it \n",
        "    # is useful for visualizing convergence and debugging\n",
        "    hist = {'beta': [], 'L': []}\n",
        "    # initialize\n",
        "    beta = beta0\n",
        "    # Loop over iterations\n",
        "    for it in range(nit):\n",
        "        # Evaluate the function and gradient\n",
        "        L, Lgrad = grad_func(beta)\n",
        "        # Take a gradient step\n",
        "        beta = beta - lr*Lgrad\n",
        "         # Save history\n",
        "        hist['L'].append(L)\n",
        "        hist['beta'].append(beta)\n",
        "    # Convert to numpy arrays\n",
        "    hist['L'] = np.array(hist['L'])\n",
        "    hist['beta'] = np.array(hist['beta'])\n",
        "   \n",
        "    return beta, L, hist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1koh4lfuGpUy"
      },
      "source": [
        "We now run the gradient descent starting from a initial condition of $\\boldsymbol{\\beta}_0 = \\vec{0}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "wUQlqAeLGpUy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "620fdd16-303e-4f4e-c452-127abf512dbc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Initial condition\n",
        "beta0 = np.zeros(p)\n",
        "\n",
        "# Parameters\n",
        "nit = 2000\n",
        "lr = 1e-5\n",
        "\n",
        "# Run the gradient descent\n",
        "beta, L, hist = grad_opt_simp(Leval_param, beta0, lr=lr, nit=nit)\n",
        "\n",
        "# Plot the training loss\n",
        "t = np.arange(nit)\n",
        "plt.plot(t, hist['L'])\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzNucOTmGpUz"
      },
      "source": [
        "We can measure the accuracy of the final estimate by creating a predict method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqD-fT40GpUz"
      },
      "outputs": [],
      "source": [
        "def predict(X,beta):\n",
        "    z = X@beta\n",
        "    yhat = (z > 0)\n",
        "    return (1*yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "xKFRxS0nGpUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b70b1c9-d5b8-45f7-9878-07d1ff358106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy = 0.941435\n"
          ]
        }
      ],
      "source": [
        "yhat = predict(X,beta)\n",
        "acc = np.mean(yhat == y)\n",
        "print(\"Train accuracy = %f\" % acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGSTLqqbGpU0"
      },
      "source": [
        "This is not quite as good as the accuracy for the `sklearn` method from the demo, which was about 98.5%.  The reason is that the learning rate was somewhat slow and we didn't yet fully converge.\n",
        "\n",
        "To see the effect of the learning rate, the code below tries different learning rates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ip3NuUPGpU0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "f5ac0789-fed3-4af3-eac7-f68abac6d0a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lr=    1.00e-05  Train accuracy = 0.941435\n",
            "lr=    1.00e-04  Train accuracy = 0.969253\n",
            "lr=    1.00e-03  Train accuracy = 0.970717\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4664895ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 215
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Learning rate values to test\n",
        "lr_test = [1e-5,1e-4,1e-3]\n",
        "ntest = len(lr_test)\n",
        "\n",
        "# Strings for the legend\n",
        "leg_str = []\n",
        "\n",
        "beta0 = np.zeros(p)\n",
        "for i in range(ntest):\n",
        "    # Run the optimizer\n",
        "    beta, L, hist = grad_opt_simp(Leval_param, beta0, lr=lr_test[i], nit=nit)    \n",
        "    \n",
        "    # Plot the results\n",
        "    plt.semilogy(t, hist['L'])\n",
        "    leg_str.append(\"lr=%12.2e\" % lr_test[i])\n",
        "    \n",
        "    # Measure the train accuracy\n",
        "    yhat = predict(X,beta)\n",
        "    acc = np.mean(yhat == y)\n",
        "    print(\"lr=%12.2e  Train accuracy = %f\" % (lr_test[i], acc))\n",
        "    \n",
        "plt.grid()\n",
        "plt.legend(leg_str, loc='upper right')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAjaxffyGpU0"
      },
      "source": [
        "We see that increasing the learning rate, speeds the convergence time, but the optimization is beginning to go unstable. It recovers from this instability for learning rate `1e-3`, but try running with rate `1e-2` to see more of an issue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZkdfE06GpU1"
      },
      "source": [
        "## Adaptive Step Size\n",
        "\n",
        "The above example shows that gradient descent is sensitive to the step size.  We now consider a variant of gradient descent with an adaptive step-size using the Armijo rule discussed in class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnZJvxOTGpU1"
      },
      "outputs": [],
      "source": [
        "def grad_opt_adapt(grad_func, beta0, nit=2000, lr_init=1e-4):\n",
        "    \"\"\"\n",
        "    Gradient descent optimization with adaptive step size\n",
        "    \n",
        "    feval:  A function that returns f, fgrad, the objective\n",
        "            function and its gradient\n",
        "    beta0:  Initial estimate\n",
        "    nit:    Number of iterations\n",
        "    lr:     Initial learning rate\n",
        "    \"\"\"\n",
        "    \n",
        "    # Set initial point\n",
        "    beta = beta0\n",
        "    lr = lr_init\n",
        "    \n",
        "    # Create history dictionary for tracking progress per iteration.\n",
        "    # This isn't necessary if you just want the final answer, but it \n",
        "    # is useful for debugging\n",
        "    hist = {'lr': [], 'beta': [], 'L': []}\n",
        "\n",
        "    L,Lgrad = grad_func(beta0)\n",
        "    for it in range(nit):\n",
        "        # Take a gradient step\n",
        "        beta1 = beta - lr*Lgrad\n",
        "        # Evaluate the test point by computing the objective function, L1,\n",
        "        # at the test point and the predicted decrease, df_est\n",
        "        L1, Lgrad1 = grad_func(beta1)\n",
        "        df_est = Lgrad.T@(beta1-beta)\n",
        "        \n",
        "        # Check if test point passes the Armijo condition\n",
        "        alpha = 0.5\n",
        "        if (L1-L < alpha*df_est) and (L1 < L):\n",
        "            # If descent is sufficient, accept the point and increase the learning rate\n",
        "            lr = lr*2\n",
        "            L = L1\n",
        "            Lgrad = Lgrad1\n",
        "            beta = beta1\n",
        "        else:\n",
        "            # Otherwise, decrease the learning rate\n",
        "            lr = lr/2            \n",
        "            \n",
        "        # Save history\n",
        "        hist['L'].append(L)\n",
        "        hist['lr'].append(lr)\n",
        "        hist['beta'].append(beta0)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    for elem in ('L', 'lr', 'beta'):\n",
        "        hist[elem] = np.array(hist[elem])\n",
        "        \n",
        "    return beta, L, hist\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6gKouOMGpU1"
      },
      "source": [
        "We can now run the new optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tU3YbmkxGpU1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "8c423c71-9267-4f3b-a593-9d49d20cd574"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "beta0 = np.zeros(p)\n",
        "nit = 2000\n",
        "beta, L, hist = grad_opt_adapt(Leval_param, beta0, nit=nit)\n",
        "\n",
        "t = np.arange(nit)\n",
        "plt.subplot(2,1,1)\n",
        "plt.semilogy(t, hist['L'])\n",
        "plt.grid()\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.loglog(t, hist['lr'])\n",
        "plt.grid()\n",
        "plt.ylabel('Learning rate')\n",
        "plt.xlabel('Iteration')\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD4EcuGZGpU2"
      },
      "source": [
        "Finally we measure the accuracy and see that we performed as well as the best fixed step size used above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RAkPpzfGpU2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "134988d0-d838-4e05-af6b-4de1badfad1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy = 0.970717\n"
          ]
        }
      ],
      "source": [
        "yhat = predict(X,beta)\n",
        "acc = np.mean(yhat == y)\n",
        "print(\"Train accuracy = %f\" % acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fSBbJOBGpU3"
      },
      "source": [
        "## L2 Regularization\n",
        "\n",
        "Just as for linear regression, given enough features, logsitic regression can be prone to overfitting. In such cases, it often make sense to add regularization when training. In particular, instead of minimizing:\n",
        "$$\n",
        "L(\\mathbf{\\boldsymbol{\\beta}}) =\\sum_{i=1}^n (1-y_i)(\\mathbf{x}_i^T\\boldsymbol{\\beta}) - \\log(h(\\mathbf{x}_i^T\\boldsymbol{\\beta})).\n",
        "$$\n",
        "we might use $\\ell_2$ regularization and choose $\\beta$ to minimize\n",
        "$$\n",
        "L_R(\\boldsymbol{\\beta}) = L(\\boldsymbol{\\beta}) + \\lambda \\|\\boldsymbol{\\beta}\\|_2^2\n",
        "$$\n",
        "for some regularization parameter $\\lambda$. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def Leval(beta,X,y):\n",
        "#     \"\"\"\n",
        "#     Compute the loss and gradient given beta,X,y\n",
        "#     \"\"\"\n",
        "#     z = X@beta \n",
        "#     # 𝐱𝑇𝑖𝜷\n",
        "#     h = 1/(1+np.exp(-z))\n",
        "#     L = np.sum((1-y)*z - np.log(h))\n",
        "#     # Gradient\n",
        "#     Lgrad = (X.T)@(h-y)\n",
        "#     return L, Lgrad"
      ],
      "metadata": {
        "id": "dPVwe0Kq85fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZT1V-K3vGpU3"
      },
      "outputs": [],
      "source": [
        "def Leval_reg(beta,X,y,lamb):\n",
        "    \"\"\"\n",
        "    Compute the regularized loss and gradient given beta, X, y, and regularization parameter lamb\n",
        "    \"\"\"\n",
        "    z = X@beta\n",
        "    h = 1/(1+np.exp(-z))\n",
        "    L = np.sum((1-y)*z - np.log(h))\n",
        "    Lr = L + lamb*np.transpose(beta)@beta\n",
        "    Lgrad = (X.T)@(h-y)\n",
        "    Lrgrad = Lgrad + 2*lamb*beta\n",
        "    return Lr, Lrgrad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqZ_CVJOGpU3"
      },
      "source": [
        "As we did above for the unregularized loss, write code to test your gradient computation. Run your test for `lamb` equals `0`,`1`,`10`,`100` and print output which confirms the accuracy of your gradient in all cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caxEu-uaGpU4"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "# p = X.shape[1]\n",
        "# beta0 = np.random.randn(p)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = X.shape[1]\n",
        "beta0 = np.random.randn(p)\n",
        "lambs = [0,1,10,100]\n",
        "Leval_reg_param = lambda beta:Leval_reg(beta,X,y,lamb)\n",
        "nlambs = len(lambs)\n",
        "# Perturb the point\n",
        "step = 1e-6\n",
        "beta1 = beta0 + step*np.random.randn(p)\n",
        "# Measure the function and gradient at w0 and w1\n",
        "for i in range(nlambs):\n",
        "    lamb = lambs[i]\n",
        "    L0, Lgrad0 = Leval_reg_param(beta0)\n",
        "    L1, Lgrad1 = Leval_reg_param(beta1)\n",
        "    # Predict the amount the function should have changed based on the gradient\n",
        "    dL_est = Lgrad0.T@(beta1-beta0)\n",
        "    print(\"Lambda = \", lamb)\n",
        "    # Print the two values to see if they are close\n",
        "    print(\"Actual L1-L0    = %12.4e\" % (L1-L0))\n",
        "    print(\"Predicted L1-L0 = %12.4e\" % dL_est)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyeYDOcD-s-R",
        "outputId": "7e40107f-a5b3-4aa8-b2ec-5a00ed806dbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lambda =  0\n",
            "Actual L1-L0    =  -2.5097e-03\n",
            "Predicted L1-L0 =  -2.5097e-03\n",
            "Lambda =  1\n",
            "Actual L1-L0    =  -2.5205e-03\n",
            "Predicted L1-L0 =  -2.5205e-03\n",
            "Lambda =  10\n",
            "Actual L1-L0    =  -2.6169e-03\n",
            "Predicted L1-L0 =  -2.6169e-03\n",
            "Lambda =  100\n",
            "Actual L1-L0    =  -3.5818e-03\n",
            "Predicted L1-L0 =  -3.5818e-03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XEK-AO_GpU4"
      },
      "source": [
        "For `lamb` equals `0`,`1`,`10`,`100` use `grad_opt_adapt` run for `2000` iterations with $\\boldsymbol{\\beta}_0 = \\vec{0}$ to find a parameter vector $\\beta$ which approximately minimizes $L_R(\\beta)$. For each regularization level, print the train accuracy achieved when using the optimal parameters. Note that we expect the **train accuracy to decrease** as the regularization parameter increases. Regularization often helps **test accuracy to increase**, but for this lab we're keeping things simple without a test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nE4WvpRGpU4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c48af9c7-8cf2-4229-d585-f059b8deabc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lamb =  0 Train accuracy = 0.970717\n",
            "lamb =  1 Train accuracy = 0.969253\n",
            "lamb =  10 Train accuracy = 0.959004\n",
            "lamb =  100 Train accuracy = 0.920937\n"
          ]
        }
      ],
      "source": [
        "# TODO\n",
        "\n",
        "# You can now pass a parameter like w0\n",
        "# Lr0, Lrgrad0 = Leval_param(beta0)\n",
        "# print(L0)\n",
        "p = X.shape[1]\n",
        "beta0 = np.zeros(p)\n",
        "lambs = [0,1,10,100] \n",
        "nlambs = len(lambs)\n",
        "trainings = []\n",
        "nit = 2000\n",
        "for i in range(nlambs):\n",
        "  lamb = lambs[i]\n",
        "  beta, L, hist = grad_opt_adapt(Leval_reg_param, beta0, nit = nit)\n",
        "  yhat = predict(X,beta)\n",
        "  acc = np.mean(yhat == y)\n",
        "  trainings.append(acc)\n",
        "  print(\"lamb = \", lamb, \"Train accuracy = %f\" % acc)\n",
        "\n",
        "# These are the outputs I got:\n",
        "# lamb = 0, Train accuracy = 0.970717\n",
        "# lamb = 1, Train accuracy = 0.969253\n",
        "# lamb = 10, Train accuracy = 0.959004\n",
        "# lamb = 100, Train accuracy = 0.920937"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kctkbgn3GpU5"
      },
      "source": [
        "## Kernel Logistic Regression, Linear Kernel\n",
        "\n",
        "Logistic regression works nicely with non-linear kernels, which can significantly improve its accuracy for certain problems. We will see an example in our next lab on classifying MNIST images. \n",
        "\n",
        "To use logistic regression with a kernel, our first step was to reparameterize the logistic loss function by replacing $\\boldsymbol{\\beta}\\in \\mathbb{R}^d$ with $\\mathbf{X}^T\\boldsymbol{\\alpha}$ where $\\boldsymbol{\\alpha}\\in \\mathbb{R}^n$ is a new parameter vector.  \n",
        "\n",
        "Our loss becomes:\n",
        "$$\n",
        "L(\\boldsymbol{\\alpha}) =\\sum_{i=1}^n (1-y_i)(\\mathbf{x}_i^T\\mathbf{X}^T\\boldsymbol{\\alpha}) - \\log(h(\\mathbf{x}_i^T\\mathbf{X}^T\\boldsymbol{\\alpha})).\n",
        "$$\n",
        "\n",
        "When using kernel methods we also typically need to uses some sort of regularization. Again, we use simple $\\ell_2$ regularization, which leads to the regularized loss:\n",
        "$$\n",
        "L_R(\\boldsymbol{\\alpha}) = L(\\boldsymbol{\\alpha}) + \\lambda \\|\\mathbf{X}^T\\boldsymbol{\\alpha}\\|_2^2\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A74HTaPZGpU5"
      },
      "source": [
        "Write a function which evaluates the regularized loss `Lr` for parameters `alpha` and also computes the gradient $\\nabla L_R(\\boldsymbol{\\alpha})$ at `alpha`. You will have to derive an expression for this gradient to implement your function. \n",
        "\n",
        "**Note**: We are not doing anything with a non-linear kernel yet, but we will in the next lab! Here we are just going through the first step of reformulating our logistic regression model to eventually use different kernels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hySKDFkGpU5"
      },
      "outputs": [],
      "source": [
        "def Leval_reg_linear_kernel(alpha,X,y,lamb):\n",
        "    \"\"\"\n",
        "    Compute the regularized loss and gradient given beta, X, y, and regularization parameter lamb\n",
        "    \"\"\"\n",
        "    # TODO\n",
        "    # Lr =\n",
        "    # Lrgrad\n",
        "    # z = X@beta\n",
        "    # h = 1/(1+np.exp(-z))\n",
        "    # L = np.sum((1-y)*z - np.log(h))\n",
        "    # Lr = L + lamb*np.transpose(beta)@beta\n",
        "    # Lgrad = (X.T)@(h-y)\n",
        "    # Lrgrad = Lgrad + 2*lamb*beta\n",
        "    # return Lr, Lrgrad\n",
        "    z = X@(X.T@alpha)\n",
        "    h = 1/(1+np.exp(-z))\n",
        "    L = np.sum((1-y)*z - np.log(h))\n",
        "    Lgrad = X.T@(h-y)\n",
        "    Lr = L + lamb*((X.T@alpha).T)@(X.T@alpha)\n",
        "    Lrgrad = (Lgrad + 2*lamb*(X.T@alpha))@X.T\n",
        "\n",
        "    return Lr, Lrgrad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvR6KWxNGpU6"
      },
      "source": [
        "Once we obtain a parameter vector $\\alpha$, as shown in class, we predict a label by computing $\\mathbf{x}_{new}^T \\mathbf{X}^T\\boldsymbol{\\alpha}$ and checking if the value is greater than or equal to zero. For a matrix of testing data points $\\mathbf{X}_{test}$ where each row is a new test data point, we can implement prediction as follows for the linear (inner-product) kernel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWdmnTrKGpU6"
      },
      "source": [
        "Even though our reformuation leads to an equivalent loss function and regularization term, the updates performed by the gradient descent optimizer are not exactly the same. In fact, after reparameterization, we can see that gradient descent converges much more slowly to a solution. \n",
        "\n",
        "To see this your self, run `grad_opt_adapt` for `5000` steps to minimize the regularized logistic regression loss for data `X`,`y` with `lamb = 10`, using both the original formulation (involving `beta`) and the reparameterized formulation, involving `alpha`. Plot the history of how the loss function decreases over time a single plot with two lines: one for the original formulation and one for the reparameterization. Include axis labels and a legend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRgOSxQTGpU7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "3258a24c-f24b-41d0-a6ec-89da9058cf4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 225
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAACCCAYAAACO/1WsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAa50lEQVR4nO3deZxU1Znw8d9TS1fTC003DQKCtAjGQQ2iRElcQGMMGrcxRiXGaHRwSGKMyWxmxolv3tf3jZr3MxNNHI0Lo4lRiRtxN8awaBYVBAVEpQURBES27qabXqr7mT/OKbuoFFBddauru/r5fj73U/eee+rcc4qinj73nnuuqCrGGGNMEEKFroAxxpjiYUHFGGNMYCyoGGOMCYwFFWOMMYGxoGKMMSYwFlSMMcYEJlLoChRabW2t1tXVZfXe5uZmysvLg61QH2dtHhiszcUv1/YuWbJkq6oOS00f8EGlrq6OxYsXZ/XeBQsWMH369GAr1MdZmwcGa3Pxy7W9IrIuXbqd/jLGGBMYCypZevuV39G+7hVo3FjoqhhjTJ9hQSVbL/w7p639f/Dbbxe6JsYY02dYUMnS7VXXsF2qoLWh0FUxxpg+w4JKljaV1PGOjIfO9kJXxRhj+gwLKlkKixAnDJ0dha6KMcb0GRZUshQJC21EradijDFJLKhkKSRCo1TC9jWw7b1CV8cYY/oECypZioSEx0KnuY2HL4WuzsJWyBhj+gALKlkKhYR1jIJTroPNy+Hp7xe6SsYYU3ADfpqWbEVCQpcqnPRPsP19WHIv1B4Kn7X7VowxA5f1VLIUCgmd6jfOugUO+iw8/6/w7vMFrZcxxhSSBZUsRUKCJoJKOAIzH4Sqg+CRy+GDvxS0bsYYUygWVLIUlqSeCsCgarjsKYgNhgcvgq31BaubMcYUigWVLIVDQpemJFaPhYt/40aC3fMF2PJ2QepmjDGFUpRBRUTOFZG7RGSuiJyWj2OkDSoAI46ES5+Ejt3wq7+FHe/n4/DGGNMn5T2oiEhYRJaKyFM5lDFHRLaIyIo0+2aIyDsiUi8i1wKo6jxVnQXMBi7MvvZ7F06M/kpn1FFw+XNussn//hJsXZ2PKhhjTJ/TGz2V7wKr0u0QkeEiUpmSNj5N1nuBGWneHwZuA04HJgIzRWRiUpbr/P7AhUMp11RSjToKLn0COtvg7lPhw9fzUQ1jjOlT8hpURGQ08CXg7r1kmQbME5GYzz8L+FlqJlVdBGxP8/5jgXpVXaOq7cBDwDni3AQ8q6p5+TXf6+mvZKOnwGXPQLQM5syA+hfzURVjjOkz8t1T+Snwz0BXup2q+jDwPDBXRC4GLge+0oPyDwTWJ21v8GnfAU4FzheR2eneKCJnicidDQ3ZPQ8lLMLueAYZhx0KVzwPQw6CBy6E5Y9kdTxjjOkP8hZURORMYIuqLtlXPlW9GWgFbgfOVtVduR5bVW9V1WNUdbaq3rGXPE+q6pVVVVVZHWPnbjflfVs8gzm/hhwEs16EkZPg0Stg/o+hK22cNcaYfi2fPZXjgbNF5H3caalTROT+1EwiciJwBPA4cH0Pj/EhMCZpe7RPy7vDRrhLQa0dGQaH0io3KmziubDwRpj7NWhtzGMNjTGm9+UtqKjqD1R1tKrWARcBf1DVryXnEZHJwJ3AOcA3gKEickMPDvMaMEFEDhaREn+cJwJpwH7EomEA2uM96HGUlMFX7oUv/B949zm49wxo3JifChpjTAEU+j6VMuACVX1PVbuArwPrUjOJyIPAn4FPicgGEbkCQFXjwFW46zKrgN+o6sreqHgs7D66jE5/JROB46+GC37pnsNyxwmw7s95qKExxvS+XpmlWFUXAAvSpP8xZbsDuCtNvpn7KPsZ4JmcK9lDsWgiqGR5beRvzoRZ8+H+L8N9Z8EZN8Mx33BBxxhj+qlC91T6rVjEfXStHTk8nGv4YTD7Jag7AZ76Hjw2C9pyHqdgjDEFY0ElS4mb6TftbM2toLIa+Nqj8NmrYPnDcNfJsOnN3CtojDEFYEElS6OrywDY3/2PGQmF4Yv/Fy55HHbvhLtOgYU/sUcUG2P6HQsqWSqNBnD6K9Uhp8C3/gyHnQHzb4C7P29T6Btj+hULKlmKRdyQ4kCDCkB5rRsZdv4cN8PxL06EV++ymyWNMf2CBZUsleY6+mt/jvgyzH4ZxhwHz/wj3P+3bgiyMcb0YRZUspS4+THwnkqyqtHuOsuMm2DDErj9c7DgRmhvzt8xjTEmBxZUspT3nkqCCEydDd9ZDIfOgAU/hp8dA6/dA/H2/B7bGGN6yIJKlkrCIQRoy2dPJVnlCLjgPjeVftUYePr7Lri8MddGiRlj+gwLKlkSEcICGxtyvE+lp+qOhyt+Bxc/6uYSe/xK+MU0e1aLMaZPsKCSg7hCg58Cv1eJwIRT4Zt/hvPugpatcP95cO+ZsHFp79fHGGM8Cyo5GFEmFHSmrlAIPn0BXL0UTv1f8NFKuPNkePK70JLuQZnGGJNfFlRyUBYVdvfWNZV9iQ6CE74HV78OU78Jr/8Kfv4ZWPag3d9ijOlVFlRyEAvD7vY+EFQSBlXDjB/D3y+E6jqYNxt+fgz88RZobyl07YwxA0BGQUVEykUk5NcPFZGzRSSa36r1fbFwH+mppBpxJFz+HJx7O5TVwgs/hP86Dup/3z0TpjHG5EGmPZVFQKmIHAj8DrgEuDdfleovSvpaTyVZOApHfRX+7gWYORcQ9+yW/zwC5n3bHgxmjMmLTB/SJara4p+4+F+qerOILMtnxfqDWFhoaemjQSXZp2bAuOmw4lH3GONVT8Cy+12P5qivwaQL3akzY4zJUaY9FRGRzwIXA0/7tHB+qtR/xML0zdNf6URLYfLFcOGv4B/egRk3QigCz/0L3DwO7jsblj1gU8AYY3KSaVC5BvgB8LiqrhSRccD8/FUrNyJyrojcJSJzReS0fB2nJCw07O5A+9t1ipIyN0rsygXukcbHXwM718G8b8JPJsCjfwernrIAY4zpsYxOf6nqQmAhgL9gv1VVr97Xe0SkFHctJuaP84iqXp9NJUVkDnAmsEVVj0jZNwO4BddzultVb1TVecA8EakG/j/uOlDgQv4mlXXbWqirLc/HIfLvwKPd8vkfwro/wZtz3emx5Q9DZJC7g3/s8e5ZLyM+XejaGmP6uExHfz0gIoNFpBxYAbwlIv+0n7e1Aaeo6iTgKGCGiExNKXe4iFSmpI1PU9a9wIw09QoDtwGnAxOBmSIyMSnLdX5/Xowf4j6+nYW4qz5oIi6AnH0r/ONquGQeHH0JNGyAF38Ed06Dn4zj8BU3uue7bFwKnUXQbmNMoDK9UD9RVRtF5GLgWeBaYAnwk729Qd05oV1+M+qX1PNE04DZInKGqraJyCzgPFyQSC5rkYjUpTnMsUC9qq4BEJGHgHNEZBVwI/Csqr6eYRt7rCLquio7W4pstuBwFA452S0ATZthzQJYs5DKt3/vnu8CEC2HMZ9xPZgDj4aRR7n7Y6Sg8wwYYwoo06AS9felnAv8XFU7RGS/FxJ8T2IJMB64TVVfSd6vqg+LyMHAXBF5GLgc+EIP6n8gsD5pewNwHPAd4FSgSkTGq+odaep2FnDW+PHpOkaZKfNBpSDzf/WmyhEw6SKYdBF/WbCA6ZPq4MPX3emy9a/AK3dApw+spUPcqLKRk+CAw91SMw5ilfs8hDGmOGQaVH4BvA+8ASwSkbFA4/7epKqdwFEiMgR4XESOUNUVKXlu9j2M24FDVHVXurJ6QlVvBW7dT54ngSenTJkyK9vjlA+UoJKqus4tR5zntuNtsOUt2LgMNr0Bm5fDa3dDPGkG5/LhMOxTfjkMaifA0AkweJT1bIwpIpleqE/9kV4nIidnehBV3Ski83HXRfYIKiJyInAE8DhwPXBVpuUCHwJjkrZH+7ReUe7nFGhoGWBBJVUkBqMmuyWhMw471sJHK2D7Wvco5K3vuOe/tDd154uWw9BxLsBU17lezdDxUHOwC0Qhm0nImP4ko6AiIlW4H/yTfNJC4H8DDft4zzCgwweUQbjTWjel5JkM3Ikb2bUW+LWI3KCq12VY/9eACf4U2ofARcBXM3xvziIhoawkPPB6KpkIR1xvpHbCnumq0LQJtq6Gre/CtnoXcDa+7kaddcWTyoh1B5qqA2HIWKge6x5SVl3nbti0Xo4xfUqmp7/m4HoYF/jtS4D/xl1U35uRwH3+ukoI+I2qPpWSpwy4QFXfAxCRrwOXpRYkIg8C04FaEdkAXK+q96hqXESuAp7HDSmeo6orM2xTIAaXRnl7c9P+MxpHxJ3yGjwKxk3bc19nHBo+gG1rXC9n5wewfY3r6XzwJ2hN+RsmUgpVo6FyZHeZlaPcNaDKkf51hBt4YIzpFZkGlUNU9ctJ2z/a3zQtqvomMHk/ef6Yst0B3JUm38x9lPEM8My+jpNP7Z1d/eeu+r4uHHG9kppx6ffv3ulu0ty53r02bnRDnps2uUEDTZv27OkkDKpJCjQjofIAd2qtYjhUHOCW8loorbKejzE5yjSo7BaRE1T1ZQAROR7Ynb9q9R9TxlazbptNK98rBg1xy8hJ6fd3dbmnYDZtcsOgmzZB4yZo3gJNH7ntLW/Bri2gaf4QCJdA+TAoG+qCTPkwKKvloI8aYcm67n1lNe61dIhd8zEmRaZBZTbwS39tBWAHcGl+qtS/1JSXsHT9zkJXw4D7ga/wPZC9BR5wwWf3dhdcdn3kluatLvg0b/XLx+56T/NWxnW0wNpf/XU5EnKBpazG9YbKhrrrPIOqoay6e31QjQuGpVUuf2kVhAb81HmmSGU6+usNYJKIDPbbjSJyDfBmPivXH1SXl7CzpR1VRezUSf8QCvmeSC0cMHG/2Re9+DwnTTncBZqWbe5Rzc1bXWBq2d792rDBDafevQM69jVvmkBsMAxKCjJ7LEOgdLBbjw1267FKv17l1iOx4D4PYwKUaU8FcMEkafP7wE+DrU7/U10WpaNTaW7vpCLWo4/T9BNd4ZgbEFA1OvM3xdtccNm9wwWc1ga/7Eza3umuE7U1ugEJrY0uvT2DgR/hEh9oKqGksns9VuHTKtwSS7wm0sp9WtJ7ooPsWpIJTC6/gvYtBKrLSgDY0dxuQcV0i8S6R5/1VGfcBZpEIGprctttTW7ZI21X92vTJti2y62374KODK/1SeivAtGk5g7YNMYFoZKy7oCUWKI+/ZPXMp9e5oJUSbkLfBasBpxcfgX72Xzv+VFT7oLK9uZ2xtSUFbg2piiEI34wQE1u5XR1uscXtCcCTVN3wElstzYmbe9ywap9F6GmjbDjfXcar70Z2lt8kOrBf3sJ+0AzyC9lKa8paZFS99yfyKDu/ZHSv35NzheJuXQLYH3GPoOKiDSR/lskwKC81KifqU4ElWKbVNL0f6GwvzYzuMdvXbpgAdOnT98zUdUFlkSgSgSa9mb/2uKDUPJrC3TsTnrd7abvaf7Y7Y/7tMS6dmXf3kTAiZS6YJNYwrGktHT7SiBSytgPNsIf3/TpJT5vic+TSEt5TbceigzoALfPoKKqNgvgftT4019vbWzk5E8NL3BtjMkjke7TX+Thu67qHqcQ3w0drd0BJzkYxVv9epvbH29L2vb7P1lv617vbHfXsOLt/n3t0LlnvoNRN8NhziQp2ERdUApHuwNP8nokTVo4CqFo+vRwdC95/HookrLfbyfWQz5vKEI43uI+84ADoF0EyNHIIaUAdHbZ2UBjciLiew0lbpRbb1Jl4fwXmXb8cUkBp80Fo3irT0uk+9fODp8nKe2TfO1uf6Kcrnh3eYn0zg53urGzY8+0zo6kfL6sdPdV5ehEgKmr3RD8AFlQyVEsEqY0GmJXW5o7uY0x/YMIGor4EXGFrkwaXZ17Bpuuju5glUjv6tgzKO2xL979vs4O6Irz3rtvc0geHklhQSUAFbEoTa0WVIwxeRIKuyVaGliR61sXcEg0+EvjNsdEACpiYeupGGMMFlQCUR6L0GJBxRhjLKgEoTwW4cW3txS6GsYYU3AWVAIwKOomB7QRYMaYgc6CSgCmHToMgEZ7AqQxZoCzoBKAav+werur3hgz0FlQCUBiUslX124vcE2MMaawLKgEYPKYagA27bSHYRpjBjYLKgGoKosyYnApmxpaC10VY4wpKAsqARlRVcrCdz8udDWMMaagLKgEpLaihC1NbbR2BD/xmzHG9BcWVAJywZQxgF2sN8YMbBZUAnLMWHex/rmVmwtcE2OMKRwLKgEZWhHjsBGV/GGVTddijBm4LKgE6IwjR7K5sZWXV28tdFWMMaYgLKgEaOaxBwHwwKvrClwTY4wpDAsqARpWGWPquBqeWb6ZLptc0hgzAFlQCdj5x7hRYHe/vKbANTHGmN5nQSVg5x41ikhIuOX3q4l3dhW6OsYY06uKMqiIyLkicpeIzBWR03rz2JFwiKs/P4Hm9k4eePWD3jy0McYUXN6CioiMEZH5IvKWiKwUke/mUNYcEdkiIivS7JshIu+ISL2IXAugqvNUdRYwG7gw+1Zk5++njWN4ZYwbnl7FR402H5gxZuDIZ08lDvyDqk4EpgLfFpGJyRlEZLiIVKakjU9T1r3AjNREEQkDtwGnAxOBmSnHuM7v71WxSJhbZ06mPd7FrF8utqlbjDEDRt6CiqpuUtXX/XoTsAo4MCXbNGCeiMQARGQW8LM0ZS0C0s1/cixQr6prVLUdeAg4R5ybgGcTdehtU8cN5cfnHcmbGxr43txltMUtsBhjil+vXFMRkTpgMvBKcrqqPgw8D8wVkYuBy4Gv9KDoA4H1SdsbfNp3gFOB80Vk9l7qdJaI3NnQ0NCDw/XMzGMP4ppTJ/Dsis1cNuc1tu1qy9uxjDGmL8h7UBGRCuBR4BpVbUzdr6o3A63A7cDZqror12Oq6q2qeoyqzlbVO/aS50lVvbKqqirXw+3TNaceyk1fPpLX3t/OF3/6Ek+8sRFVu4fFGFOc8hpURCSKCyi/VtXH9pLnROAI4HHg+h4e4kNgTNL2aJ/Wp1z4mYN47Fufo7aihKsfXMrpt7zEQ69+QMPujkJXzRhjAhXJV8EiIsA9wCpV/Y+95JkM3AmcCawFfi0iN6jqdRke5jVggogcjAsmFwFfzbnyefDp0UN4+uoTefT1Dcx5eS3XPracf//tCiYfVM2UsdX8zcjBjB9ewZiaMipieftnMcaYvMrnr9fxwCXAchFZ5tP+VVWfScpTBlygqu8BiMjXgctSCxKRB4HpQK2IbACuV9V7VDUuIlfhrsuEgTmqujJfDcpVOCRcMGUMXzlmNEvX7+T5lZv5U/02frFoDZ1J07oMLo0wrDJGdVkJFaURymMRKkoiRCNCNBzyixAJhQiJBF7PfRW5dm07b3au7nmZOdRnr2XmoVBJU+iaNe2s1PrgD5aDvLQ96V9pzZp2VvFe7mXmpZ55KFPgvbUdvBvKvc2flJmHmgb5edav7eC4z3UyqCQcXKGADPTz+1OmTNHFixdn9d4FCxYwffr0nOvQFu+kfssu1nzczPodLXzU0MrHu9rY0dxBc3ucXa1xmtvjdHQqHfEuOrq6iHcqcZtfzBiTg8XXnUptRSyr94rIElWdkppu51n6gFgkzOGjqjh8VM8GDagqQf9NsL/iFi5cwLRp03tWZh7+cMlHON1bNRctWshJJ03Lrsw81LQ3/g5ctGgRJ510Uk5l5KOe+fw8X3rpJU488cRgygyklJQyA/5AX375ZWrKSgItEyyo9GsikpfTC/sSEiEc6ulBe7mSAYuEhJJIUc5otFclYaE0Guxpkb6uNCKUD6DrmYMiQqjH/5f3b2D9TzHGGJNXFlSMMcYEZsBfqBeRj4FsH9VYCwy0ZwdbmwcGa3Pxy7W9Y1V1WGrigA8quRCRxelGPxQza/PAYG0ufvlqr53+MsYYExgLKsYYYwJjQSU3dxa6AgVgbR4YrM3FLy/ttWsqxhhjAmM9FWOMMYGxoJIFEZkhIu+ISL2IXFvo+uRCROaIyBYRWZGUViMiL4jIav9a7dNFRG717X5TRI5Oes+lPv9qEbm0EG3JlIiMEZH5IvKWiKwUke/69KJtt4iUisirIvKGb/OPfPrBIvKKb9tcESnx6TG/Xe/31yWV9QOf/o6IfLEwLcqMiIRFZKmIPOW3i7q9ACLyvogsF5FlIrLYp/Xed9vNH2VLpgtuNuT3gHFACfAGMLHQ9cqhPScBRwMrktJuBq7169cCN/n1M4BncfOuTAVe8ek1wBr/Wu3Xqwvdtn20eSRwtF+vBN4FJhZzu33dK/x6FPcU1qnAb4CLfPodwDf9+reAO/z6RcBcvz7Rf+djwMH+/0K40O3bR7u/DzwAPOW3i7q9vs7vA7Upab323baeSs8dC9Sr6hpVbQceAs4pcJ2ypqqLgO0pyecA9/n1+4Bzk9J/qc5fgCEiMhL4IvCCqm5X1R3AC8CM/Nc+O6q6SVVf9+tNwCrcY6iLtt2+7omnqkb9osApwCM+PbXNic/iEeDz/hlJ5wAPqWqbqq4F6nH/J/ocERkNfAm4228LRdze/ei177YFlZ47EFiftL3BpxWTA1R1k1/fDBzg1/fW9n77mfjTHJNxf7kXdbv9qaBlwBbcj8R7wE5VjfssyfX/pG1+fwMwlP7V5p8C/wx0+e2hFHd7ExT4nYgsEZErfVqvfbcHzpScJiuqqiJSlEMERaQC97jra1S1UZKmfC7GdqtqJ3CUiAzBPb77sAJXKW9E5Exgi6ouEZHpha5PLztBVT8UkeHACyLydvLOfH+3rafScx8CY5K2R/u0YvKR7wLjX7f49L21vd99JiISxQWUX6vqYz656NsNoKo7gfnAZ3GnOxJ/XCbX/5O2+f1VwDb6T5uPB84Wkfdxp6hPAW6heNv7CVX90L9uwf3xcCy9+N22oNJzrwET/CiSEtxFvScKXKegPQEkRntcCvw2Kf3rfsTIVKDBd6mfB04TkWo/quQ0n9Yn+XPl9wCrVPU/knYVbbtFZJjvoSAig4Av4K4lzQfO99lS25z4LM4H/qDuCu4TwEV+tNTBwATg1d5pReZU9QeqOlpV63D/R/+gqhdTpO1NEJFyEalMrOO+kyvoze92oUcq9McFN2LiXdw56X8rdH1ybMuDwCagA3fe9ArcueQXgdXA74Ean1eA23y7lwNTksq5HHcRsx74RqHbtZ82n4A77/wmsMwvZxRzu4FPA0t9m1cAP/Tp43A/kvXAw0DMp5f67Xq/f1xSWf/mP4t3gNML3bYM2j6d7tFfRd1e3743/LIy8fvUm99tu6PeGGNMYOz0lzHGmMBYUDHGGBMYCyrGGGMCY0HFGGNMYCyoGGOMCYwFFWOMMYGxoGKMMSYwFlSMMcYE5n8ADi74xB54H48AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "nit = 5000\n",
        "lamb = 10\n",
        "beta0 = np.zeros(X.shape[1])\n",
        "alpha0 = np.zeros(X.shape[0])\n",
        "# TODO\n",
        "# Optimize alpha via gradient descent\n",
        "# Optimize beta via gradient descent\n",
        "# Generate plot with labels and legend\n",
        "\n",
        "beta, L, hist = grad_opt_adapt(Leval_reg_param, beta0, nit=nit)\n",
        "\n",
        "Leval_reg_linear_kernel_param = lambda alpha0: Leval_reg_linear_kernel(alpha0,X,y,lamb)\n",
        "beta_new, L_new, hist_new = grad_opt_adapt(Leval_reg_linear_kernel_param, alpha0, nit=nit)\n",
        "\n",
        "\n",
        "t = np.arange(nit)\n",
        "# t2 = np.arange(nit)\n",
        "plt.subplot(2,1,1)\n",
        "plt.semilogy(t, hist['L'])\n",
        "plt.semilogy(t, hist_new['L'])\n",
        "plt.grid()\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "\n",
        "# t2 = np.arange(nit)\n",
        "# plt.subplot(2,1,2)\n",
        "# plt.semilogy(t2, hist_new['L'])\n",
        "# plt.grid()\n",
        "# plt.ylabel('Loss with alpha')\n",
        "# plt.tight_layout()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13L6Rt3fGpU7"
      },
      "source": [
        "After `5000` steps, what is the minimum regularized objective function value acheived for each formulation of the problem? "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2Hd08zJGpU8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f01a158-00a1-4711-cbb2-7bcb7afc9afa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189.25006637226753\n",
            "258.63541382568604\n"
          ]
        }
      ],
      "source": [
        "# TODO \n",
        "# Print minimum objective values\n",
        "beta_min = min(hist['L'])\n",
        "alpha_min = min(hist_new['L'])\n",
        "print(beta_min)\n",
        "print(alpha_min)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lmd_XuNGpU8"
      },
      "source": [
        "Fortunately, when gradient descent converges slowly, there are other first-order optimization algorithms that can be used in its place, and often converge much faster. Here we will try using some built-in optimization methods for the `scipy` library in Python. In particular, we use the function `scipy.optimize.minimize` which is documented [here](https://docs.scipy.org/doc/scipy-0.13.0/reference/generated/scipy.optimize.minimize.html).\n",
        "\n",
        "This function takes many inputs. The two most important ones are the `fun` and `jac` arguments, which should be passed Python functions for 1) evaluating the function we want to minimize at an point and 2) evaluating the gradient of the function at any point. `jac` is short for \"Jacobian\" which is a generalization of the gradient for multi-output functions. Since we're dealing with loss function which just have one output, the Jacobian is equal to the gradient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYWaKz4gGpU8"
      },
      "source": [
        "Run the code below for minimizing the reparameterized regularized loss using the [\"BFGS\" algorithm](https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBZAn0yfGpU8"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8FE7opPGpU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b82b9456-ed61-4302-a919-77ac53c90f0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "189.2500663722634"
            ]
          },
          "metadata": {},
          "execution_count": 236
        }
      ],
      "source": [
        "l = 10\n",
        "# function for computing regularized loss\n",
        "f = lambda alpha: Leval_reg_linear_kernel(alpha,X,y,l)[0]\n",
        "# function for computing gradient of regularized loss\n",
        "g = lambda alpha: Leval_reg_linear_kernel(alpha,X,y,l)[1]\n",
        "alpha0 = np.zeros(X.shape[0])\n",
        "# res stores the result of scipy.optimize.minimize, which contains a number of pieces of information\n",
        "res = scipy.optimize.minimize(f, alpha0, args=(), method='BFGS', jac=g) \n",
        "# we're most interest in the minimizing argument, which can be obtained via res.x\n",
        "alpha = res.x\n",
        "# we check the objective value obtained\n",
        "Leval_reg_linear_kernel(alpha,X,y,l)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rthjCLb8GpU9"
      },
      "source": [
        "You should observe a loss much closer to minimum obtained before reparameterization (which is very close to the true minimum), and the method runs in a fraction of the time that gradient descent would have required! You can time how long the solvers take to converge using the following code. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3aeHRY1GpU9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d728ae2-f136-4c44-f15d-18d3811c55a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solver time: 0.0027420520782470703\n",
            "Minimum loss value: 189.2500663722634\n"
          ]
        }
      ],
      "source": [
        "t = time.time()\n",
        "scipy.optimize.minimize(f, alpha0, args=(), method='newton-cg', jac=g) \n",
        "elapsed = time.time() - t\n",
        "print(\"Solver time: \" + str(elapsed))\n",
        "alpha = res.x\n",
        "print(\"Minimum loss value: \" + str(Leval_reg_linear_kernel(alpha,X,y,l)[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uovufY3vGpU9"
      },
      "source": [
        "Refering the documentation try out different algorithms for `scipy.optimize.minimize`. Find a first-order method (only requires gradients) which provides a comparable solution to `BFGS` but in less time. Note the method here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dILVm9cdGpU9"
      },
      "outputs": [],
      "source": [
        "# TODO What's a faster method? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the result, 'newton-cg' is a faster method. \n"
      ],
      "metadata": {
        "id": "lctQHG39CMYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = time.time()\n",
        "# scipy.optimize.minimize(f, alpha0, args=(), method='newton-cg', jac=g) \n",
        "res = scipy.optimize.minimize(f, alpha0, args=(), method='BFGS', jac=g) \n",
        "elapsed = time.time() - t\n",
        "print(\"Solver time: \" + str(elapsed))\n",
        "alpha = res.x\n",
        "print(\"Minimum loss value: \" + str(Leval_reg_linear_kernel(alpha,X,y,l)[0]))"
      ],
      "metadata": {
        "id": "lKbtZeK-fet2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74f1dbcc-4ab5-4e3e-8504-f7f6011e9c0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solver time: 1.4945833683013916\n",
            "Minimum loss value: 189.2500663722634\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Simao (Alice) Chen's Lab 3",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}